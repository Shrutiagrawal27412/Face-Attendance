{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.10.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "print(cv2.__version__)\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "#python imaging lib- open, save and manipulate images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.face' has no attribute 'LBPHFaceRecognizer_create'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m recognizer \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLBPHFaceRecognizer_create\u001b[49m()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#local binary program LBPH\u001b[39;00m\n\u001b[0;32m      3\u001b[0m detector \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mCascadeClassifier(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:/OneDrive/Desktop/project2/haarcascade_frontalface_default.xml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2.face' has no attribute 'LBPHFaceRecognizer_create'"
     ]
    }
   ],
   "source": [
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "#local binary program LBPH\n",
    "detector = cv2.CascadeClassifier('D:/OneDrive/Desktop/project2/haarcascade_frontalface_default.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.face' has no attribute 'LBPHFaceRecognizer_create'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m recognizer \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLBPHFaceRecognizer_create\u001b[49m()\n\u001b[0;32m      2\u001b[0m detector\u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mCascadeClassifier( \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:/OneDrive/Desktop/project2/haarcascade_frontalface_default.xml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2.face' has no attribute 'LBPHFaceRecognizer_create'"
     ]
    }
   ],
   "source": [
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "detector= cv2.CascadeClassifier( 'D:/OneDrive/Desktop/project2/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageAndLabels(path):\n",
    "    imagePaths= [os.path.join(path,f) for f in os.listdir(path)]\n",
    "    #jitni path ke andar images hai, unka path nikal ke store kara\n",
    "    faceSamples = []\n",
    "    Ids = []\n",
    "    for imagePath in imagePath:\n",
    "        pilImage = Image.open(imagePath).convert('L') #grayscale me convert used in PIL\n",
    "        #L also means lumisence\n",
    "        #for grayscale and pil= do L\n",
    "        imageNp= np.array(pilImage, 'uint8')\n",
    "        Id= int(os.path.split(imagePath)[-1].split(\".\"[1]))\n",
    "        faces= faceCascade.detectMultiScale(imageNp)\n",
    "        for(x,y,w,h) in faces:\n",
    "            faceSamples.append(imageNP[y:y+h, x:x+w])\n",
    "            Ids.append(Id)\n",
    "        return faceSamples, Ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'imagePath' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m faces, Ids\u001b[38;5;241m=\u001b[39m \u001b[43mgetImageAndLabels\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m, in \u001b[0;36mgetImageAndLabels\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      4\u001b[0m faceSamples \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m Ids \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m imagePath \u001b[38;5;129;01min\u001b[39;00m \u001b[43mimagePath\u001b[49m:\n\u001b[0;32m      7\u001b[0m     pilImage \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(imagePath)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#grayscale me convert used in PIL\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m#L also means lumisence\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m#for grayscale and pil= do L\u001b[39;00m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'imagePath' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "faces, Ids= getImageAndLabels('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s= recognizer.train(faces, np,array(Ids))\n",
    "print(\"Training done!\")\n",
    "\n",
    "recognizer.write('trainer/trainer.yml')\n",
    "#yml= extension. data stored in 0 1 for machine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
